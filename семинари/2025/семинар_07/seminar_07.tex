\documentclass{scrartcl}
\usepackage{graphicx}  % required for inserting images
\usepackage{float}

% for cyrillic and Bulgarian language
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[bulgarian]{babel}

% math packages
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{ragged2e}  % adds FlushLeft

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    language=Octave,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,
    captionpos=b,
    keepspaces=false,                 
    %numbers=left,                    
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    basicstyle=\ttfamily\footnotesize,
    columns=fullflexible
}

\lstset{style=mystyle}

\title{Семинар 07}
\author{Ивайло Андреев}
\date{03 април 2025}

\begin{document}
\maketitle  % template title

\section{Уводни бележки от линейната алгебра}

Както ще стане ясно, линейните диференциални уравнения се основават на теорията на линейната алгебра и затова ще дадем някои уводни бележки от апарата на линейната алгебра.

\subsection{Линеен оператор - дефиниция}

Нека $V$ и $W$ са линейни пространства над полето $\mathbb{R}$ (или $\mathbb{C}$). Оператор $T: V \to W$ се нарича \textbf{линеен}, ако за всякакви два вектора $u, v \in V$ и произволно число $\alpha \in \mathbb{R}$ (или $\mathbb{C}$) са изпълнени следните свойства:

\begin{itemize}
    \item \textbf{Адитивност}: $T(u + v) = T(u) + T(v)$
    \item \textbf{Хомогенност}: $T(\alpha u) = \alpha T(u)$
\end{itemize}

Тези две условия гарантират, че действието на оператора $T$ запазва линейната структура на пространството.

\subsection{Линеен оператор - пример}

\textbf{Пример 1: Диференциране}

Разгледаме оператор $D: C^1(\mathbb{R}) \to C(\mathbb{R})$, който съпоставя на всяка гладка функция нейната производна:
\[ D(f) = f' \]
За две функции $f, g \in C^1(\mathbb{R})$ и произволно число $\alpha$, имаме:
\begin{align*}
    D(f + g) &= (f + g)' = f' + g' = D(f) + D(g) \\
    D(\alpha f) &= (\alpha f)' = \alpha f' = \alpha D(f)
\end{align*}
Следователно, операторът на диференциране е линеен.

\textbf{Пример 2: Интегриране}

Разглеждаме оператор $I: C(\mathbb{R}) \to C^1(\mathbb{R})$, дефиниран чрез:
\[ I(f)(x) = \int_{a}^{x} f(t)\, dt \]
За две функции $f, g \in C(\mathbb{R})$ и константа $\alpha$:
\begin{align*}
    I(f + g)(x) &= \int_{a}^{x} (f(t) + g(t))\, dt = \int_{a}^{x} f(t)\, dt + \int_{a}^{x} g(t)\, dt = I(f)(x) + I(g)(x) \\
    I(\alpha f)(x) &= \int_{a}^{x} \alpha f(t)\, dt = \alpha \int_{a}^{x} f(t)\, dt = \alpha I(f)(x)
\end{align*}
Следователно, операторът на интегриране също е линеен.

\subsection{Линеен оператор - контра-пример}

Нека разгледаме оператор $T: \mathbb{R} \to \mathbb{R}$, дефиниран чрез:
\[ T(x) = |x| \]
Да проверим дали е линеен:
\begin{itemize}
    \item Нека $x = 1$ и $y = -1$. Тогава:
    \[ T(x + y) = T(1 + (-1)) = T(0) = 0 \]
    но
    \[ T(x) + T(y) = |1| + |-1| = 1 + 1 = 2 \neq 0. \]
    Това нарушава свойството на адитивност.
    
    \item Нека $x = 1$ и $\alpha = -1$. Тогава:
    \[ T(\alpha x) = T(-1) = |-1| = 1 \]
    но
    \[ \alpha T(x) = (-1) \cdot |1| = -1. \]
    Това нарушава свойството на хомогенност.
\end{itemize}
Следователно, операторът $T(x) = |x|$ не е линеен.


\subsection{Хомогенни системи от линейни уравнения. Базисни вектори и фундаментална система решения (ФСР)}

Нека имаме следната хомогенна система от линейни уравнения:

$$
\begin{cases}
    x_1+x_2+2x_3=0\\
    2x_1+x_2+3x_3=0
\end{cases}
$$

Нека припомним, че системата е от линейни уравнения, защото са линейно по $x$-овете, тоест нямаме $x_1x_2$, $x_1^2$, $\sqrt{x_2}$, $|x_3|$ или други нелинейности. Системата е хомогенна защото дясната страна са нули (и нямаме свободни членове константи).

Нека също си припомним как можем да запишем системата в еквивалентен матричен запис:

$$
\begin{pmatrix}
    1 & 1 & 2\\
    2 & 1 & 3
\end{pmatrix}
\begin{pmatrix}
    x_1\\x_2\\x_3
\end{pmatrix}
=
\begin{pmatrix}
    0\\0
\end{pmatrix}
$$

Нека също си припомним умножението на матрици и размерности - умножавайки матрици с размерности $2\times 3$ и $3\times 1$ вътрешната размерност "пада" и остава $2\times 1$, каквато е и размерността на вектор-стълбът от дясната страна на равенството.

$$
\begin{pmatrix}
    1 & 1 & 2\\
    2 & 1 & 3
\end{pmatrix}
\sim
\begin{pmatrix}
    1 & 1 & 2\\
    0 & -1 & -1
\end{pmatrix}
$$

$$
\begin{cases}
    x_1+x_2+2x_3=0\\
    -x_2 - x_3=0
\end{cases}
$$

Откъдето

$$x_1 = -3; \quad x_2 = -x_3$$

Така общото решение е

$$(-x_3, -x_3, x_3) = x_3(-1, -1, 1)$$

Следователно базисните вектори са $$(-1, -1, 1)$$ и ФСР - множеството от базисни вектори се задава по следния начин

$$\text{ФСР} = \{(-1, -1, 1)\}$$

\section{Бърза справка}

Нека разгледаме следното ДУ

$$y' = \lambda y$$

Търсим ненулеви решения.

Това е уравнение с разделени променливи и можем да разделим на $y$, стремейки се да получим ненулеви решения

$$\dfrac{y'}{y} = \lambda$$

Интегрираме по $x$

$$\int \dfrac{y'}{y} \space dx = \int \lambda \space dx$$

$$\int \dfrac{1}{y} \space dy = \lambda \int dx$$

$$\ln{|y|} = \lambda x + C_1$$

$$|y| = \mathrm{e}^{\lambda x + C_1}$$

$$y = C \mathrm{e}^{\lambda x}$$

Нека забележим каква е структурата на даденото диференциално уравнение и какъв тип решение получаваме. Ще е важно за по-нататъчни наблюдения.

\section{Увод в линейните диференциални уравнения}

Линейно ОДУ от ред $n$ в най-общия смисъл има вида:

$$a_0(x)y^{(n)}(x) + a_1(x)y^{(n-1)}(x) + \dots + a_n(x)y(x) = f(x)$$

където $a_j(x)$ са комплекснозначни функции от вида:

$$g := a_j(x) = u(x) + \mathrm{i}v(x)$$

където $u: \Delta \rightarrow \mathbb{R}$ е реалната част на $g$ и $v: \Delta \rightarrow \mathbb{R}$ е имагинерната част на $g$ и $\Delta$ е някакъв (отворен) интервал.

Ако функциите $a_j(x)$ НЕ зависят явно от $x$, то казваме, че уравнението е с постоянни коефициенти.

Ако $f(x) \equiv 0$, то казваме, че уравнението е хомогенно. Иначе е нехомогенно.

Ако уравнението е хомогенно, то очевидно $y \equiv 0$ е решение. Ще се интересуваме от ненулеви решения.

\subsection{Реални и различни собствени стойности}

Нека разгледаме следното линейно хомогенно обикновено диференциално уравнение от втори ред:

$$y'' - 4y' - 5y = 0$$

\subsubsection{Свеждане до система}

Ще сведем това линейно уравнение до линейна система от диференциални уравнения.

Нека $y_1 = y$ и нека $y_2 = y'$.

Диференцирайки получаваме $y_1' = y'$ и $y_2' = y''$.

От уравнението изразяваме $y'' = 5y + 4y'$.

Така получаваме следната система, еквивалентна на даденото уравнение:

$$
\begin{cases}
y_1' = y_2\\
y_2' = 5y_1 + 4y_2
\end{cases}
$$

Ще я запишем с еквивалентен матричен запис

$$
\begin{pmatrix}
y_1'\\ y_2'
\end{pmatrix}
=
\begin{pmatrix}
0 & 1\\ 5 & 4
\end{pmatrix}
\begin{pmatrix}
y_1\\ y_2
\end{pmatrix}
$$

$$Y' = AY$$

Можем да забележим, че това матрично уравнение е пълен аналог на по-простото диференциално уравнение, разгледано във втора точка.

Така както е системата не можем да я решим директно, а бихме искали. Бихме могли да я решим директно ако системата имаше следния вид:

$$
\begin{cases}
y_1' = \alpha_{1}y_1\\
y_2' = \alpha_{2}y_2
\end{cases}
$$

Ще сведем системата до такава с такъв вид. От съображения на матрично умножение, можем да отбележим, че свеждане в такъв вид е възможно само ако матрицата $A$ е диагонална, тоест има ненулеви елементи само по главния диагонал. Тези ненулеви стойности ще са именно собствените стойности на $A$.

\subsubsection{Диагонализиране}

Ще диагонализираме матрицата $A$. Хубаво е да припомним, че не всяка матрица може да се диагонализира, в този случай ще можем. За целта ще приложим следните стъпки:
\begin{enumerate}
    \item Намираме собствените стойности на матрицата $A$
    \item Намираме собствените вектори, съответстващи на собствените стойности
    \item Формираме преходната матрица $M$
    \item Намираме обратната матрица на преходната
    \item Намираме диагоналната матрица $D = M^{-1}AM$
\end{enumerate}

\paragraph{Собствени стойности}

Собствените стойности на матрицата $A$ ще намерим като решим равенството:

$$det(A-\lambda E) = 0$$

$$
\begin{vmatrix}
-\lambda & 1 \\ 5 & 4-\lambda
\end{vmatrix}
= 0
$$

$$-\lambda(4-\lambda) - 1\times5 = 0$$

$$\lambda^2 - 4\lambda - 5 = 0$$

Забележете, че коефициентите на този полином са същите като на първоначалното линейно диференциално уравнение. Това е неслучайно. В бъдеще директно ще казваме, че този полином е характеристичен полином на линейното диференциално уравнение. Нарича се така, защото това е характеристичен полином на матрицата $A$, която е матрица на системата от диференциални уравнения, еквивалентна на даденото уравнение.

Връщайки се към сметките получаваме две реални и различни собствени стойности

$$\lambda_1 = 5;\quad \lambda_2 = -1$$

\paragraph{Собствени вектори}

Нека $\overrightarrow{u}$ и $\overrightarrow{v}$ са ненулеви собствените вектори, съответстващи на собствените стойности.

За $\overrightarrow{u}$

$$\lambda_1 = 5 \longleftrightarrow \overrightarrow{u}$$

$$
\overrightarrow{u} =
\begin{pmatrix}
    u_1\\u_2
\end{pmatrix}
\ne 0
$$

$$(A-\lambda_1 E)\overrightarrow{u} = 0$$

$$
\begin{pmatrix}
    -5 & 1\\
    5 & -1
\end{pmatrix}
\begin{pmatrix}
    u_1\\
    u_2
\end{pmatrix}
=
\begin{pmatrix}
    0\\
    0
\end{pmatrix}
$$

$$
\begin{cases}
    -5u_1+u_2=0\\
    5u_1-u_2=0
\end{cases}
$$

$$u_2=5u_1$$

$$
u =
\begin{pmatrix}
    u_1\\u_2
\end{pmatrix}
=
\begin{pmatrix}
    u_1\\5u_1
\end{pmatrix}
=
\begin{pmatrix}
    1\\5
\end{pmatrix}
$$

За $\overrightarrow{v}$

$$\lambda_1 = -1 \longleftrightarrow \overrightarrow{u}$$

$$
\overrightarrow{v} =
\begin{pmatrix}
    v_1\\v_2
\end{pmatrix}
\ne 0
$$

$$(A-\lambda_2 E)\overrightarrow{v} = 0$$

$$
\begin{pmatrix}
    1 & 1\\
    5 & 5
\end{pmatrix}
\begin{pmatrix}
    v_1\\
    v_2
\end{pmatrix}
=
\begin{pmatrix}
    0\\
    0
\end{pmatrix}
$$

$$
\begin{cases}
    v_1+v_2=0\\
    5v_1+5v_2=0
\end{cases}
$$

$$v_1=-v_2$$

$$
v =
\begin{pmatrix}
    v_1\\v_2
\end{pmatrix}
=
\begin{pmatrix}
    -v_2\\v_2
\end{pmatrix}
=
\begin{pmatrix}
    1\\-1
\end{pmatrix}
$$

\paragraph{Преходна матрица}

Със сметнатите собствени вектори за преходната матрица получаваме

$$
M =
\begin{pmatrix}
    \overrightarrow{u} & \overrightarrow{v}
\end{pmatrix}
=
\begin{pmatrix}
    1 & 1\\5 & -1
\end{pmatrix}
$$

\paragraph{Обратна на преходната матрица}

Искаме да намерим обратната на $M$

\[
\left(
\begin{array}{cc|cc}
1 & 1 & 1 & 0 \\
5 & -1 & 0 & 1
\end{array}
\right)\sim
\]

\[
\left(
\begin{array}{cc|cc}
1 & 1 & 1 & 0 \\
0 & -6 & -5 & 1
\end{array}
\right)\sim
\]

\[
\left(
\begin{array}{cc|cc}
1 & 1 & 1 & 0 \\
0 & 1 & \frac{5}{6} & -\frac{1}{6}
\end{array}
\right)\sim
\]

\[
\left(
\begin{array}{cc|cc}
1 & 0 & \frac{1}{6} & \frac{1}{6} \\
0 & 1 & \frac{5}{6} & -\frac{1}{6}
\end{array}
\right)
\]


$$
M^{-1} =
\begin{pmatrix}
    \frac{1}{6} & \frac{1}{6} \\ \frac{5}{6} & -\frac{1}{6}
\end{pmatrix}
$$

\paragraph{Диагонална матрица}

За диагоналната матрица получаваме:

$$
D = M^{-1}AM =
\begin{pmatrix}
    5 & 0 \\ 0 & -1
\end{pmatrix}
$$

И съответно за $A$ имаме равенството:

$$A = MDM^{-1}$$

\subsubsection{Преобразуване на системата}

Имаме матричния запис

$$Y' = AY$$

Заместваме с полученото разлагане за $A$

$$Y' = MDM^{-1}Y$$

$$M^{-1}Y' = DM^{-1}Y$$

$$(M^{-1}Y)' = D(M^{-1}Y)$$

Полагаме

$$
Z = M^{-1}Y =
\begin{pmatrix}
    z_1\\z_2
\end{pmatrix}
$$

$$Z' = DZ$$

$$
\begin{pmatrix}
    z_1'\\z_2'
\end{pmatrix}
=
\begin{pmatrix}
    5 & 0 \\ 0 & -1
\end{pmatrix}
\begin{pmatrix}
    z_1\\z_2
\end{pmatrix}
$$

Записваме в еквивалентен запис на система

$$
\begin{cases}
    z_1' = 5z_1\\
    z_2' = -z_2
\end{cases}
$$

Това обаче е система, която можем да решим директно по начина, описан в точка 2. Решението има вида

$$
\begin{cases}
    z_1 = C_1\mathrm{e}^{5x}\\
    z_2 = C_2\mathrm{e}^{-x}
\end{cases}
$$

\subsubsection{Окончателен отговор и коментари}

Така по естествен начин с апарата на линейната алгебра получихме възможни решения във вид на експоненциални функции. Нещо повече, можем да твърдим, че тези решения образуват фундаментална система решения на решенията на първоначалното линейно хомогенно диференциално уравнение.

$$\text{ФСР} = \{\mathrm{e}^{5x},\space \mathrm{e}^{-x}\}$$

Това означава, че линейната обвивка (всички възможни решения на линейното диференциално уравнение) се задават като линейна комбинация на функциите от ФСР по следния начин:

$$y(x) = C_1\mathrm{e}^{5x} + C_2\mathrm{e}^{-x}$$

За пълнота остава да направим няколко неща:

\begin{enumerate}
    \item Да се върнем към $y_1$ и $y_2$
    \item Да проверим, че $y_1 = y$ "лежи" в линейната обвивка на пространството от решения
    \item Да проверим, че $y_1' = y_2$
    \item Да покажем, че функциите от ФСР са линейно независими
\end{enumerate}

\paragraph{Връщане на полагането}

Вече като сме намерили $z_1$ и $z_2$, ще намерим $y_1$ и $y_2$

$$
Z = M^{-1}Y =
\begin{pmatrix}
    z_1\\z_2
\end{pmatrix}
=
\begin{pmatrix}
    \frac{1}{6} & \frac{1}{6}\\\frac{5}{6} & -\frac{1}{6}
\end{pmatrix}
\begin{pmatrix}
    y_1\\y_2
\end{pmatrix}
$$

$$
\begin{cases}
    \dfrac{1}{6}y_1 + \dfrac{1}{6}y_2 = z_1 = C_1\mathrm{e}^{5x}\\
    \dfrac{5}{6}y_1 - \dfrac{1}{6}y_2 = z_2 = C_2\mathrm{e}^{-x}
\end{cases}
$$

$$
\begin{cases}
    y_1 + y_2 = 6C_1\mathrm{e}^{5x}\\
    5y_1 - y_2 = 6C_2\mathrm{e}^{-x}
\end{cases}
$$

Събираме редовете и получаваме

$$6y_1 = 6C_1\mathrm{e}^{5x} + 6C_2\mathrm{e}^{-x}$$

$$y_1 = C_1\mathrm{e}^{5x} + C_2\mathrm{e}^{-x}$$

Заместваме в първия ред и получаваме

$$y_2 = 5C_1\mathrm{e}^{5x} - C_2\mathrm{e}^{-x}$$

Така получихме решенията

$$
\begin{cases}
    y_1 = C_1\mathrm{e}^{5x} + C_2\mathrm{e}^{-x}\\
    y_2 = 5C_1\mathrm{e}^{5x} - C_2\mathrm{e}^{-x}
\end{cases}
$$

\paragraph{Проверка за принадлежност към линейната обвивка}

Както казахме искаме да проверим дали $y_1 = y$ "лежи" в линейната обвивка от решения на даденото линейно диференциално уравнение. Очевидно е така, тъй като явния вид на $y_1$ изцяло съвпада с общото решение на диференциалното уравнение.

\paragraph{Проверка при диференциране}

Както казахме искаме да проверим дали $y_1' = y2$, защото това положихме първоначално за да получим система и искаме да се уверим, че равенството е изпълнено.

$$y_1' = 5C_1\mathrm{e}^{5x} - C_2\mathrm{e}^{-x} = y_2$$

Равенството е изпълнено.

\paragraph{Линейна независимост на функциите във ФСР}

От линейната алгебра знаем, че линейната комбинация на елементите от ФСР е линейна обвивка на линейното пространство и също, че елементите от ФСР са линейно независими. Проверихме първото, сега ще проверим и линейната независимост по два начина - по стандартната дефиниция от линейната алгебра и чрез детерминанта на Вронски.

\textbf{Първи начин}

Приравняваме линейната комбинация на елементите от ФСР на 0 и искаме да покажем, че има тъждество само ако всичко константи са нули

$$a_1\mathrm{e}^{5x} + a_2\mathrm{e}^{-x} = 0$$

$$a_1\mathrm{e}^{5x} = - a_2\mathrm{e}^{-x}$$

$$a_1\mathrm{e}^{6x} = - a_2$$

Равенството е изпълнено за всяко $x$ само ако $a_1 = a_2 = 0$, откъдето функциите са линейно независими по дефиниция.

\textbf{Втори начин}

Ще използваме детерминантата на Вронски. Тя има вида

$$
\begin{vmatrix}
    \phi_1 & \phi_2\\
    \phi_1' & \phi_2'
\end{vmatrix}
= 0
$$

където $\phi_1$ и $\phi_2$ са базисните функции от ФСР. Лема гласи, че ако за всяко $x$ в някакъв интервал детерминантата на Вронски е ненулева, то функциите са линейно независими в този интервал.

$$
\begin{vmatrix}
    \mathrm{e}^{5x} & \mathrm{e}^{-x}\\
    5\mathrm{e}^{5x} & -\mathrm{e}^{-x}
\end{vmatrix}
= 0
$$

$$-\mathrm{e}^{5x}\mathrm{e}^{-x} - 5\mathrm{e}^{5x}\mathrm{e}^{-x} = 0$$

$$-6\mathrm{e}^{4x} = 0$$

От свойствата на функцията $\mathrm{e}^{\alpha x}$ е ясно, че равенството не е изпълнено за никое $x$. Тоест детерминантата на Вронски е ненулева за всяко $x$ от реалната права и съответно по лемата функциите са линейно независими.

\subsection{Комплексни собствени стойности}

Нека разгледаме следното линейно хомогенно обикновено диференциално уравнение от втори ред:

$$y'' + 4y' + 5y = 0$$

Следната система е еквивалентна на това линейно диференциално уравнение:

$$
\begin{cases}
    y_1' = y_2\\
    y_2' = -5y_1 - 4y_2
\end{cases}
$$

Характеристичния полином на $A$, който съответства на характеристичният полином на уравнението, се задава по следния начин:

$$det(A-\lambda E) = 0$$

$$\lambda^2 + 4\lambda + 5 = 0$$

$$\lambda_{1,2} = -2\pm i$$

Така диагоналната матрица ще има вида:

$$
D =
\begin{pmatrix}
    -2+i & 0\\
    0 & -2-i
\end{pmatrix}
$$

Така $Z$, съответстващ на линейна трансформация на $Y$, има вида:

$$Z' = DZ$$

$$
\begin{pmatrix}
    z_1'\\z_2'
\end{pmatrix}
=
\begin{pmatrix}
    -2+i & 0\\
    0 & -2-i
\end{pmatrix}
\begin{pmatrix}
    z_1\\
    z_2
\end{pmatrix}
$$

Следната система е еквивалентна на този матричен запис:

$$
\begin{cases}
    z_1' = (-2+i)z_1\\
    z_2' = (-2-i)z_2
\end{cases}
$$

Тази система можем да решим директно и получаваме решенията:

$$
\begin{cases}
    z_1 = C_1\mathrm{e}^{(-2+i)x} = C_1\mathrm{e}^{-2x}\mathrm{e}^{ix}\\
    z_2 = C_2\mathrm{e}^{(-2-i)x} = C_2\mathrm{e}^{-2x}\mathrm{e}^{-ix}
\end{cases}
$$

Ще използваме формулата на Ойлер, която има вида:

$$\mathrm{e}^{ix} = \cos{x} + i\sin{x}$$

Заместваме и получаваме:

$$
\begin{cases}
    z_1 = C_1\mathrm{e}^{-2x}\cos{x} + iC_1\mathrm{e}^{-2x}\sin{x}\\
    z_2 = C_2\mathrm{e}^{-2x}\cos{(-x)} + iC_2\mathrm{e}^{-2x}\sin{(-x)}
\end{cases}
$$

Използваме фактът, че $\sin{x}$ е нечетна функция и $\cos{x}$ е четна функция

$$
\begin{cases}
    z_1 = C_1\mathrm{e}^{-2x}\cos{x} + iC_1\mathrm{e}^{-2x}\sin{x}\\
    z_2 = C_2\mathrm{e}^{-2x}\cos{x} - iC_2\mathrm{e}^{-2x}\sin{x}
\end{cases}
$$

Тук лесно се вижда, че действително $z_1$ и $z_2$ са почти идентични, тоест нито едно от двете не дава повече информация от другото. Така можем да извлечем ФСР само от $z_1$. Решенията могат да са както реални, така и комплексни и затова ще вземем както реалната част на $z_1$, така и имагинерната и получените функции ще бъдат образуват ФСР.

$$\text{ФСР} = \{Re(z_1), \space Im(z_1)\}$$

$$\text{ФСР} = \{\mathrm{e}^{-2x}\cos{x}, \space \mathrm{e}^{-2x}\sin{x}\}$$

Така общото решение на хомогенното линейно диференциално уравнение се задава като линейна комбинация на функциите от ФСР

$$y(x) = C_1\mathrm{e}^{-2x}\cos{x} + C_2\mathrm{e}^{-2x}\sin{x}$$

\subsection{Реални и еднакви собствени стойности}

Нека разгледаме следното линейно хомогенно обикновено диференциално уравнение от втори ред:

$$y'' + 4y' + 4y = 0$$

Следната система е еквивалентна на това линейно диференциално уравнение:

$$
\begin{cases}
    y_1' = y_2\\
    y_2' = -4y_1 - 4y_2
\end{cases}
$$

Характеристичния полином на $A$, който съответства на характеристичният полином на уравнението, се задава по следния начин:

$$det(A-\lambda E) = 0$$

$$\lambda^2 + 4\lambda + 4 = 0$$

$$\lambda_{1,2} = -2$$

Получаваме двоен корен. Съответно ще трябва да подходим внимателно към този случай.

Получаваме една собствена стойност с алгебрична кратност 2. (алгебричната кратност ни казва каква е кратността на собствена стойност на характеристичния полином)

Ще построим собствения вектор, съответстващ на единствената собствена стойност.

$$\lambda = -2 \longleftrightarrow \overrightarrow{u}$$

$$
\overrightarrow{u} =
\begin{pmatrix}
    u_1\\u_2
\end{pmatrix}
\ne 0
$$

$$(A-\lambda E)\overrightarrow{u} = 0$$

$$
\begin{pmatrix}
    2 & 1\\
    -4 & -1
\end{pmatrix}
\begin{pmatrix}
    u_1\\
    u_2
\end{pmatrix}
=
\begin{pmatrix}
    0\\
    0
\end{pmatrix}
$$

$$
\begin{cases}
    2u_1+u_2=0\\
    -4u_1-2u_2=0
\end{cases}
$$

$$u_2=2u_1$$

$$
u =
\begin{pmatrix}
    u_1\\u_2
\end{pmatrix}
=
\begin{pmatrix}
    u_1\\2u_1
\end{pmatrix}
=
\begin{pmatrix}
    1\\2
\end{pmatrix}
$$

Така получаваме, че за тази собствена стойност с алгебрична кратност от 2 съответства един собствен вектор. Това означа, че геометричната кратност на тази собствена стойност е 1. Това означава, че матрицата не е диагонализируема. Тогава ще трябва да използваме по-обобщен случай на диагонализация - жорданова нормална форма. Тя е подобна на диагонална матрица, но позволява да имаме единици над главния диагонал. Те "компенсират" разликата между алгебричната и геометричната кратност на собствените стойности.

В нашия случай тази жорданова матрица би има следния вид

$$
J =
\begin{pmatrix}
    -2 & 1\\ 0 &-2
\end{pmatrix}
$$

Така $Z$, съответстващ на линейна трансформация на $Y$, има вида:

$$Z' = JZ$$

$$
\begin{pmatrix}
    z_1'\\z_2'
\end{pmatrix}
=
\begin{pmatrix}
    -2 & 1\\
    0 & -2
\end{pmatrix}
\begin{pmatrix}
    z_1\\
    z_2
\end{pmatrix}
$$

Следната система е еквивалентна на този матричен запис:

$$
\begin{cases}
    z_1' = -2z_1 + z_2\\
    z_2' = -2z_2
\end{cases}
$$

Можем да решим тази система, започвайки от $z_2$ и после $z_1$

$$z_2 = C_2\mathrm{e}^{-2x}$$

Заместваме в първия ред от системата и получаваме следното линейно уравнение:

$$z_1' = -2z_1 + C_2\mathrm{e}^{-2x}$$

$$z_1 = \mathrm{e}^{\int (-2) \space dx}\left(C_1 + \int \mathrm{e}^{-\int (-2) \space dx}C_2\mathrm{e}^{-2x} \space dx \right)$$

$$z_1 = \mathrm{e}^{-2 \int dx}\left(C_1 + C_2\int \mathrm{e}^{\int dx}\mathrm{e}^{-2x} \space dx \right)$$

$$z_1 = \mathrm{e}^{-2x}\left(C_1 + C_2\int \mathrm{e}^{2x}\mathrm{e}^{-2x} \space dx \right)$$

$$z_1 = \mathrm{e}^{-2x}\left(C_1 + C_2\int dx \right)$$

$$z_1 = \mathrm{e}^{-2x}\left(C_1 + C_2x \right)$$

$$z_1 = C_1\mathrm{e}^{-2x} + C_2x\mathrm{e}^{-2x}$$

$$
\begin{cases}
    z_1 = C_1\mathrm{e}^{-2x} + C_2x\mathrm{e}^{-2x}\\
    z_2 = C_2\mathrm{e}^{-2x}
\end{cases}
$$

$z_2$ не ни носи повече информация от $z_1$ и ще можем да извлечем базисните функции само от $z_1$, които са именно функциите от двете събираеми без константите.

$$\text{ФСР} = \{\mathrm{e}^{-2x}, \space x\mathrm{e}^{-2x}\}$$

И съответно общото решение на първоначалното линейно хомогенно диференциално уравнение е:

$$y(x) = C_1\mathrm{e}^{-2x} + C_2x\mathrm{e}^{-2x}$$

\section{Допълнителни коментари}

Нека покажем как би изглеждала жорданова матрица 5х5, която има 2 собствени стойности с кратности съответно 3 и 2 и с геометрични кратности съответно 1 и 1.

$$
\begin{pmatrix}
    \lambda_1 & 1 &   &   &  \\
      & \lambda_1 & 1 &   &  \\
      &   & \lambda_1 & 0 &  \\
      &   &   & \lambda_2 & 1\\
      &   &   &   & \lambda_2\\
\end{pmatrix}
$$

\end{document}